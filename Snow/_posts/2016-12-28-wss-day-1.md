---
layout: post
category: Deep Learning
title: 2nd WSS (2016) - Day 1
published: private
---
به نام خدا
===========

The 2nd Department of Computer Engineering of Sharif University of Technology's **Winter Seminar Series** is being held on December 28 & 29, 2016. Today was the first day and I want to reflect on what happened during today (Unfortunately I forgot to take any pictures, I'll try to take one or two tomorrow)

The reception started at 8:30 and I arrived around 9:00. The first keynote speaker was Professor [Hamid Nazerzadeh](http://wss.ce.sharif.edu/speakers/hamid-nazerzadeh.html#single-speaker) and his talk was titled "Real-Time Optimization of Personalized Assortments". As I didn't find the talk relevant I tried to take a nap, albeit unsuccessfully. After the first keynote talk, two sessions of three parallel talks were planned and I was planning to attend [Mohammad Babaizadeh](http://wss.ce.sharif.edu/speakers/mohammad-babaiezadeh.html#single-speaker)'s talk titled "Deep Learning at Scale". However, it got canceled :(, although it was a great opportunity to talk a little bit to Ali Eslami. Afterwards I attended [Ehsan Asgari](http://wss.ce.sharif.edu/speakers/ehsan-asgari.html#single-speaker)'s talk on "Continuous Distributed Representation of Biological Sequences and Their Applications in Bioinformatics". The talk also contained some discussion on research done in language modelling and word embeddings and results on multi-lingual word embeddings were quite interesting.

After the lunch break, the second keynote speaker was Professor [Mohammad Mahmoody](http://www.cs.virginia.edu/~mohammad/) on "Encryption and Obfuscation". Although I don't know anything about encryption and obfuscation, however I found the talk quite interesting. Apparently obfuscation is much a much harder problem than obfuscation and they had proved that you can't use results and theorems from encyption in the problem of obfuscation.

They main talk of the day I was looking forward to attend was [Ali Eslami](http://wss.ce.sharif.edu/speakers/ali-eslami.html#single-speaker)'s talk titled "Beyond Supervised Deep Learning". He presented his most recent research projects, namely "Attend, Infer, Repeat: Fast Scene Understanding with Generative Models"[[link]](http://www.arkitus.com/attend-infer-repeat/), which is a quite interesting work on learning a rich representation using a generative model (a renderer) and reinforcement learning to learn without supervision (which I plan to read the paper carefully in the near future), and " 
Unsupervised Learning of 3D Structure from Images"[[link]](http://arxiv.org/abs/1607.00662). I found the model structure for obtaining rich representations from data alone (without label supervision) thought-provoking. I usually don't read papers on these topics (not to forget my lack of mathematical understanding required for understanding these topics), but the informal and visual introduction to this models and the way rich representations are learned and are disentangled was something new that helped me get a beginner grasp of the topic. Representation learning and definition of representation is something I have been trying to think hard about for a long time and I have tried to ask about from every researcher I could find (in a face-to-face conversation). Can we evaluate a representation by itself, without evaluating it on a downstream task? In the AIR paper, the representation that the model learned on the multi-MNIST dataset could easily solve problems like determining the sum of numbers present in the image and whether left-to-right ordering of numbers was increasing or decreasing. 